# -*- coding: utf-8 -*-
"""exam_sem_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xVr3iwCnkaqqJpZha8fSsXYDsEkoU601
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install langchain openai sentence_transformers

import os
from langchain_text_splitters import CharacterTextSplitter
from sentence_transformers import SentenceTransformer
import torch.nn.functional as F
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict

os.environ["OPENAI_API_KEY"] = ""
import warnings
# Ignore all warnings
warnings.filterwarnings("ignore")

app = FastAPI()

#a function to split our answers on an appearance of new line character
def answer_splitter(answers: str)-> list[dict]:
  #create an instance of the splitter
  text_splitter = CharacterTextSplitter(
    separator = "\n",
    chunk_size = 1,
    chunk_overlap = 0,
    length_function = len
  )

  answers_split = text_splitter.split_text(answers)

  answer_stat = []
  for i in range(len(answers_split)):
    answer_stat.append(
        {
            "answer_line_len": len(answers_split[i]),
            "answer_line_text": answers_split[i],
            "answer_embedding": None
        }
    )

  return answer_stat

def answer_splitter_py(answers: str)-> list[dict]:
  answers_split = answers.split("\n")

  answer_stat = []
  for i in range(len(answers_split)):
    answer_stat.append(
        {
            "answer_line_len": len(answers_split[i]),
            "answer_line_text": answers_split[i],
        }
    )

  return answer_stat

answers_scheme ='''
In both, God’s Work of creation is still ongoing.
In both creation is the Work of a supreme being/God.
In both God continues to sustain/provide for His creation.
In both God is the source of life.
In both creation was done in an orderly manner.
In both human beings are at the centre/climax of God’s creation.
In both human beings are in charge of the creation/have authority over creation.
In both human beings are to obey/worship the creator.
In both, God created male and female
'''
answers_stud = '''
In both, the work of God is still ongoing
In both, creation is the work of god
In both, god created male and female
In both, creation has some order
In both, human beings have authority over creation
In both, God is the only source of life
'''
chunks_scheme = answer_splitter(answers_scheme)
chunks_stud = answer_splitter(answers_stud)

print(f"Marking scheme: {len(chunks_scheme)}\n Student answers: {len(chunks_stud)}")

#create embeddings for each answer
def embed(chunks: list[dict])->list[dict]:
  embedding_model = SentenceTransformer(
    model_name_or_path = "all-mpnet-base-v2",
    device = "cpu")

  sentences = []

  for i in range(len(chunks)):
    sentences.append(chunks[i].get("answer_line_text"))

  embeddings = embedding_model.encode(sentences, convert_to_tensor=True)
  embeddings_dict = dict(zip(sentences, embeddings))

  for i, embedding in enumerate(embeddings):
    chunks[i].update({"answer_embedding":embedding})

  return chunks

def cos_sim(tens1, tens2):
  return F.cosine_similarity(tens1, tens2, dim=1)

#functionize our semantic search to be used for questions with 'points' type answers
def sem_search_points(
    scheme_chunks: list[dict],
    student_chunks: list[dict])-> int:

  correct_answers = 0

  #extract the embeddings from the chunks
  scheme_embeddings = [scheme_chunks[i].get("answer_embedding") for i in range(len(scheme_chunks))]
  student_embeddings = [student_chunks[i].get("answer_embedding") for i in range(len(student_chunks))]

  similarities = {}

  for i in range(len(student_embeddings)):
    for j in range(len(scheme_embeddings)):
      key = f"student_answer{i+1}_vs_scheme_answer{j+1}"
      similarities[key]=cos_sim(student_embeddings[i].reshape(1, -1), scheme_embeddings[j])

  for pair, sim in similarities.items():
    if (sim>0.8):
      print(f"{pair}:{sim}")
      correct_answers += 1

  return correct_answers

def analyse_answers(answers_scheme: str, answers_student:str):
  return sem_search_points(embed(answer_splitter(answers_scheme)), embed(answer_splitter(answers_student)))


class Answers(BaseModel):
  scheme: str
  student: str

@app.post("/analyse")
def analyse(answers: Answers):
  try:
        return {"result": analyse_answers(answers.scheme, answers.student)}
  except Exception as e:
       raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host='0.0.0.0', port=8000)
