{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain openai sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yCksfhYBILj",
        "outputId": "eff4f656-afd9-4c2a-88f4-c83365788eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.5)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "gLPYn4UjBNxa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import langchain\n",
        "import openai\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "import nltk\n",
        "\n",
        "import warnings\n",
        "import logging\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a function to split our answers on an appearance of new line character\n",
        "def answer_splitter(answers: str)-> list[dict]:\n",
        "  #create an instance of the splitter\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = len\n",
        "  )\n",
        "\n",
        "  answers_split = text_splitter.split_text(answers)\n",
        "\n",
        "  answer_stat = []\n",
        "  for i in range(len(answers_split)):\n",
        "    answer_stat.append(\n",
        "        {\n",
        "            \"answer_line_len\": len(answers_split[i]),\n",
        "            \"answer_line_text\": answers_split[i],\n",
        "            \"answer_embedding\": None\n",
        "        }\n",
        "    )\n",
        "\n",
        "  return answer_stat"
      ],
      "metadata": {
        "id": "mOJsrSTR9qBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_splitter_py(answers: str)-> list[dict]:\n",
        "  answers_split = answers.split(\"\\n\")\n",
        "\n",
        "  answer_stat = []\n",
        "  for i in range(len(answers_split)):\n",
        "    answer_stat.append(\n",
        "        {\n",
        "            \"answer_line_len\": len(answers_split[i]),\n",
        "            \"answer_line_text\": answers_split[i],\n",
        "        }\n",
        "    )\n",
        "\n",
        "  return answer_stat\n"
      ],
      "metadata": {
        "id": "SLkDUthfGJIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers_scheme ='''\n",
        "Moses had gone up the mountain to seek God’s guidance/instructions.\n",
        "Aaron had been left in charge of the people.\n",
        "Moses delayed in returning/the people became impatient.\n",
        "Israelites asked Aaron to make them a god that would lead them.\n",
        "Aaron yielded to the demands of the Israelites/made them a golden calf to worship.\n",
        "Aaron built an altar at the foot of the mountain/put the calf.\n",
        "The people worshiped the calf/made sacriﬁces to it.\n",
        "God was angered set to destroy the Israelites.\n",
        "Moses interceded on behalf of the people.\n",
        "When Moses came down from the mountain he was angry with the people/broke the stone tablet on which the Ten Commandments were written.\n",
        "Israelite’s were given a chance to choose between following Yahweh or golden calf.\n",
        "Those who followed the golden calf were destroyed/killed\n",
        "'''\n",
        "answers_stud = '''\n",
        "Moses had gone up Mt. Sinai to talk to God\n",
        "His brother, Aaron had been left in charge of the people below the mountain\n",
        "The people became impatient when Moses delayed\n",
        "So the Israelites asked Aaron to make them a god that they could see and that would lead them\n",
        "Aaron gave in to their demands and made them a golden calf to worship\n",
        "God was angered and planned to destroy them\n",
        "Moses interceded on behalf of the people\n",
        "When Moses came down from the mountain, he was angry and broke the stone tablet that the commandements had been written on\n",
        "They were told to choose between following Yahweh or golden calf\n",
        "Those who chose to follow the golden calf were killed\n",
        "'''\n",
        "chunks_scheme = answer_splitter(answers_scheme)\n",
        "chunks_stud = answer_splitter(answers_stud)\n",
        "\n",
        "print(f\"Marking scheme: {len(chunks_scheme)}\\n Student answers: {len(chunks_stud)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM9hlSE2BeWm",
        "outputId": "d9f41b12-4a44-42c4-972c-d3b858bb91ce"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 67, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 44, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 55, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 63, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 82, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 62, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 51, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 46, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 41, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 134, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 82, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 42, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 75, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 46, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 93, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 69, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 43, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 40, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 122, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 64, which is longer than the specified 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marking scheme: 12\n",
            " Student answers: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create embeddings for each answer\n",
        "def embed(chunks: list[dict])->list[dict]:\n",
        "  embedding_model = SentenceTransformer(\n",
        "    model_name_or_path = \"all-mpnet-base-v2\",\n",
        "    device = \"cpu\")\n",
        "\n",
        "  sentences = []\n",
        "\n",
        "  for i in range(len(chunks)):\n",
        "    sentences.append(chunks[i].get(\"answer_line_text\"))\n",
        "\n",
        "  embeddings = embedding_model.encode(sentences, convert_to_tensor=True)\n",
        "  embeddings_dict = dict(zip(sentences, embeddings))\n",
        "\n",
        "  for i, embedding in enumerate(embeddings):\n",
        "    chunks[i].update({\"answer_embedding\":embedding})\n",
        "\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "YHdkj_H8IKbZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_sim(tens1, tens2):\n",
        "  return F.cosine_similarity(tens1, tens2, dim=1)"
      ],
      "metadata": {
        "id": "-kfL1kE_TPby"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#functionize our semantic search to be used for questions with 'points' type answers\n",
        "def sem_search_points(\n",
        "    scheme_chunks: list[dict],\n",
        "    student_chunks: list[dict])-> int:\n",
        "\n",
        "  correct_answers = 0\n",
        "\n",
        "  #extract the embeddings from the chunks\n",
        "  scheme_embeddings = [scheme_chunks[i].get(\"answer_embedding\") for i in range(len(scheme_chunks))]\n",
        "  student_embeddings = [student_chunks[i].get(\"answer_embedding\") for i in range(len(student_chunks))]\n",
        "\n",
        "  similarities = {}\n",
        "\n",
        "  for i in range(len(student_embeddings)):\n",
        "    for j in range(len(scheme_embeddings)):\n",
        "      key = f\"student_answer{i+1}_vs_scheme_answer{j+1}\"\n",
        "      similarities[key]=cos_sim(student_embeddings[i].reshape(1, -1), scheme_embeddings[j])\n",
        "\n",
        "  for pair, sim in similarities.items():\n",
        "    if (sim>0.8):\n",
        "      print(f\"{pair}:{sim}\")\n",
        "      correct_answers += 1\n",
        "\n",
        "  return correct_answers\n"
      ],
      "metadata": {
        "id": "YNEQUuJBWIJ3"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_search_points(embed(answer_splitter(answers_scheme)), embed(answer_splitter(answers_stud)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQpLbPuDYgnI",
        "outputId": "a6035779-73cd-439a-f053-aba9d2733810"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 49, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 53, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 58, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 34, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 47, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 64, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 80, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 53, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 41, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 36, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 36, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 32, which is longer than the specified 1\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 50, which is longer than the specified 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "student_answer1_vs_scheme_answer1:tensor([0.8861])\n",
            "student_answer2_vs_scheme_answer2:tensor([0.9037])\n",
            "student_answer3_vs_scheme_answer9:tensor([1.])\n",
            "student_answer5_vs_scheme_answer7:tensor([0.8486])\n",
            "student_answer6_vs_scheme_answer4:tensor([0.9245])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ]
}